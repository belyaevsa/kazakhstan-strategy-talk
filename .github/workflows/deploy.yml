name: Deploy to Production

on:
  push:
    branches:
      - main
  workflow_dispatch:

env:
  IMAGE_NAME: kazakhstan-strategy-app
  CONTAINER_NAME: kazakhstan-strategy
  PORT: 8080

jobs:
  deploy:
    runs-on: self-hosted

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Clean up previous build artifacts
        run: |
          echo "Cleaning up any root-owned files from previous runs..."
          docker run --rm \
            -v $PWD:/workspace \
            -w /workspace \
            alpine:latest \
            sh -c "rm -rf api/bin api/obj || true"

      - name: Build Docker image
        env:
          DOCKER_BUILDKIT: 1
        run: |
          IMAGE_TAG="${{ env.IMAGE_NAME }}:$(date +%Y%m%d-%H%M%S)-${GITHUB_SHA::7}"

          echo "Building image: $IMAGE_TAG"
          docker build \
            --build-arg VITE_GA_MEASUREMENT_ID="${{ secrets.VITE_GA_MEASUREMENT_ID }}" \
            --build-arg VITE_YANDEX_METRICA_ID="${{ secrets.VITE_YANDEX_METRICA_ID }}" \
            -t $IMAGE_TAG \
            -t ${{ env.IMAGE_NAME }}:latest \
            .

          echo "IMAGE_TAG=$IMAGE_TAG" >> $GITHUB_ENV

      - name: Run Database Migrations
        env:
          DB_HOST: ${{ secrets.DB_HOST }}
          DB_PORT: ${{ secrets.DB_PORT }}
          DB_NAME: ${{ secrets.DB_NAME }}
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          AWS_S3_BUCKET_NAME: ${{ secrets.AWS_S3_BUCKET_NAME }}
          AWS_S3_SERVICE_URL: ${{ secrets.AWS_S3_SERVICE_URL }}
        run: |
          set -e

          echo "Running database migrations..."

          # Build temporary SDK image for migrations
          docker build -f - -t migration-runner:latest . <<EOF
          FROM mcr.microsoft.com/dotnet/sdk:9.0
          WORKDIR /app
          COPY api/*.csproj ./
          RUN dotnet restore
          COPY api/ ./
          RUN dotnet tool install --global dotnet-ef
          ENV PATH="\$PATH:/root/.dotnet/tools"
          EOF

          # Run migrations using SDK image with host network
          docker run --rm \
            --network host \
            -v $PWD/api:/app \
            -e DB_HOST="$DB_HOST" \
            -e DB_PORT="$DB_PORT" \
            -e DB_NAME="$DB_NAME" \
            -e DB_USER="$DB_USER" \
            -e DB_PASSWORD="$DB_PASSWORD" \
            -e ASPNETCORE_ENVIRONMENT=Production \
            -e AWS_ACCESS_KEY_ID="$AWS_ACCESS_KEY_ID" \
            -e AWS_SECRET_ACCESS_KEY="$AWS_SECRET_ACCESS_KEY" \
            -e AWS_REGION="$AWS_REGION" \
            -e AWS_S3_BUCKET_NAME="$AWS_S3_BUCKET_NAME" \
            -e AWS_S3_SERVICE_URL="$AWS_S3_SERVICE_URL" \
            migration-runner:latest \
            dotnet ef database update

          # Clean up migration image
          docker rmi migration-runner:latest

          # Clean up root-owned files created by Docker
          echo "Cleaning up build artifacts..."
          docker run --rm \
            -v $PWD:/workspace \
            -w /workspace \
            alpine:latest \
            sh -c "rm -rf api/bin api/obj || true"

          echo "✓ Migrations completed successfully!"

      - name: Deploy New Container
        env:
          DB_HOST: ${{ secrets.DB_HOST }}
          DB_PORT: ${{ secrets.DB_PORT }}
          DB_NAME: ${{ secrets.DB_NAME }}
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          JWT_KEY: ${{ secrets.JWT_KEY }}
          JWT_ISSUER: ${{ secrets.JWT_ISSUER }}
          JWT_AUDIENCE: ${{ secrets.JWT_AUDIENCE }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          AWS_S3_BUCKET_NAME: ${{ secrets.AWS_S3_BUCKET_NAME }}
          AWS_S3_SERVICE_URL: ${{ secrets.AWS_S3_SERVICE_URL }}
          SMTP_HOST: ${{ secrets.SMTP_HOST }}
          SMTP_PORT: ${{ secrets.SMTP_PORT }}
          SMTP_USER: ${{ secrets.SMTP_USER }}
          SMTP_PASSWORD: ${{ secrets.SMTP_PASSWORD }}
          EMAIL_FROM: ${{ secrets.EMAIL_FROM }}
          EMAIL_FROM_NAME: ${{ secrets.EMAIL_FROM_NAME }}
          APP_BASE_URL: ${{ secrets.APP_BASE_URL }}
        run: |
          set -e

          # Create unique container name with git SHA
          NEW_CONTAINER="${{ env.CONTAINER_NAME }}-${GITHUB_SHA::7}"
          echo "NEW_CONTAINER=$NEW_CONTAINER" >> $GITHUB_ENV
          echo "New container: $NEW_CONTAINER"

          # Find currently running container
          CURRENT_CONTAINER=$(docker ps --filter "name=${{ env.CONTAINER_NAME }}" --format "{{.Names}}" | head -n 1)

          if [ ! -z "$CURRENT_CONTAINER" ]; then
            echo "Current running container: $CURRENT_CONTAINER"
            OLD_IMAGE=$(docker inspect --format='{{.Image}}' $CURRENT_CONTAINER)
            echo "OLD_IMAGE=$OLD_IMAGE" >> $GITHUB_ENV
            echo "OLD_CONTAINER=$CURRENT_CONTAINER" >> $GITHUB_ENV
            echo "Saved old container info for potential rollback"

            # Stop old container to free up port 8080
            echo "Stopping old container to free up port..."
            docker stop $CURRENT_CONTAINER || true
          else
            echo "No currently running container found (first deployment)"
          fi

          # Create logs directory if it doesn't exist
          mkdir -p $HOME/app-logs

          # Start new container
          echo "Starting new container: $NEW_CONTAINER"
          docker run -d \
            --name $NEW_CONTAINER \
            --restart unless-stopped \
            -p ${{ env.PORT }}:8080 \
            -v $HOME/app-logs:/app/logs \
            -e DB_HOST="$DB_HOST" \
            -e DB_PORT="$DB_PORT" \
            -e DB_NAME="$DB_NAME" \
            -e DB_USER="$DB_USER" \
            -e DB_PASSWORD="$DB_PASSWORD" \
            -e JWT_KEY="$JWT_KEY" \
            -e JWT_ISSUER="$JWT_ISSUER" \
            -e JWT_AUDIENCE="$JWT_AUDIENCE" \
            -e AWS_ACCESS_KEY_ID="$AWS_ACCESS_KEY_ID" \
            -e AWS_SECRET_ACCESS_KEY="$AWS_SECRET_ACCESS_KEY" \
            -e AWS_REGION="$AWS_REGION" \
            -e AWS_S3_BUCKET_NAME="$AWS_S3_BUCKET_NAME" \
            -e AWS_S3_SERVICE_URL="$AWS_S3_SERVICE_URL" \
            -e SMTP_HOST="$SMTP_HOST" \
            -e SMTP_PORT="$SMTP_PORT" \
            -e SMTP_USER="$SMTP_USER" \
            -e SMTP_PASSWORD="$SMTP_PASSWORD" \
            -e EMAIL_FROM="$EMAIL_FROM" \
            -e EMAIL_FROM_NAME="$EMAIL_FROM_NAME" \
            -e APP_BASE_URL="$APP_BASE_URL" \
            -e ASPNETCORE_ENVIRONMENT=Production \
            -e ASPNETCORE_URLS=http://+:8080 \
            ${{ env.IMAGE_TAG }}

          echo "✓ Started new container: $NEW_CONTAINER"

      - name: Health Check
        run: |
          set -e

          echo "Waiting for container to be healthy..."
          sleep 10

          # Health check
          for i in {1..30}; do
            if curl -f http://localhost:${{ env.PORT }}/health 2>/dev/null; then
              echo "✓ Health check passed!"
              exit 0
            fi

            if [ $i -eq 30 ]; then
              echo "✗ Health check failed after 30 attempts"
              echo "Container logs:"
              docker logs ${{ env.NEW_CONTAINER }}
              exit 1
            fi

            echo "Attempt $i/30 failed, retrying..."
            sleep 2
          done

      - name: Rollback on Failure
        if: failure()
        run: |
          echo "Health check failed, rolling back..."

          # Stop and remove failed new container
          if [ ! -z "${{ env.NEW_CONTAINER }}" ]; then
            echo "Removing failed container: ${{ env.NEW_CONTAINER }}"
            docker stop ${{ env.NEW_CONTAINER }} || true
            docker rm ${{ env.NEW_CONTAINER }} || true
          fi

          # Restart old container if it exists
          if [ ! -z "${{ env.OLD_CONTAINER }}" ] && [ ! -z "${{ env.OLD_IMAGE }}" ]; then
            echo "Restarting old container: ${{ env.OLD_CONTAINER }}"
            docker start ${{ env.OLD_CONTAINER }} || {
              echo "Failed to restart old container, recreating from image..."
              docker run -d \
                --name ${{ env.OLD_CONTAINER }} \
                --restart unless-stopped \
                -p ${{ env.PORT }}:8080 \
                -v $HOME/app-logs:/app/logs \
                -e DB_HOST="${{ secrets.DB_HOST }}" \
                -e DB_PORT="${{ secrets.DB_PORT }}" \
                -e DB_NAME="${{ secrets.DB_NAME }}" \
                -e DB_USER="${{ secrets.DB_USER }}" \
                -e DB_PASSWORD="${{ secrets.DB_PASSWORD }}" \
                -e JWT_KEY="${{ secrets.JWT_KEY }}" \
                -e JWT_ISSUER="${{ secrets.JWT_ISSUER }}" \
                -e JWT_AUDIENCE="${{ secrets.JWT_AUDIENCE }}" \
                -e AWS_ACCESS_KEY_ID="${{ secrets.AWS_ACCESS_KEY_ID }}" \
                -e AWS_SECRET_ACCESS_KEY="${{ secrets.AWS_SECRET_ACCESS_KEY }}" \
                -e AWS_REGION="${{ secrets.AWS_REGION }}" \
                -e AWS_S3_BUCKET_NAME="${{ secrets.AWS_S3_BUCKET_NAME }}" \
                -e AWS_S3_SERVICE_URL="${{ secrets.AWS_S3_SERVICE_URL }}" \
                -e SMTP_HOST="${{ secrets.SMTP_HOST }}" \
                -e SMTP_PORT="${{ secrets.SMTP_PORT }}" \
                -e SMTP_USER="${{ secrets.SMTP_USER }}" \
                -e SMTP_PASSWORD="${{ secrets.SMTP_PASSWORD }}" \
                -e EMAIL_FROM="${{ secrets.EMAIL_FROM }}" \
                -e EMAIL_FROM_NAME="${{ secrets.EMAIL_FROM_NAME }}" \
                -e APP_BASE_URL="${{ secrets.APP_BASE_URL }}" \
                -e ASPNETCORE_ENVIRONMENT=Production \
                -e ASPNETCORE_URLS=http://+:8080 \
                ${{ env.OLD_IMAGE }}
            }
            echo "✓ Rollback completed - old container is running"
          else
            echo "⚠ No old container to rollback to"
          fi

      - name: Cleanup Old Containers
        if: success()
        run: |
          set -e

          # Remove old container if it exists
          if [ ! -z "${{ env.OLD_CONTAINER }}" ]; then
            echo "Removing old container: ${{ env.OLD_CONTAINER }}"
            docker rm ${{ env.OLD_CONTAINER }} || true
          fi

          # Clean up any other old containers (keep only the current one)
          echo "Cleaning up old containers..."
          docker ps -a --filter "name=${{ env.CONTAINER_NAME }}" --format "{{.Names}}" | \
            grep -v "${{ env.NEW_CONTAINER }}" | \
            xargs -r docker rm -f || true

          # Clean up old images (keep last 3)
          echo "Cleaning up old images..."
          docker images "${{ env.IMAGE_NAME }}" --format "{{.ID}} {{.CreatedAt}}" | \
            tail -n +4 | \
            awk '{print $1}' | \
            xargs -r docker rmi -f || true

          # Remove dangling images
          docker image prune -f

          echo "✓ Deployment completed successfully!"
          echo "Active container:"
          docker ps --filter "name=${{ env.CONTAINER_NAME }}"

      - name: Final Cleanup
        if: always()
        run: |
          echo "Running final cleanup..."
          # Clean up any root-owned files
          docker run --rm \
            -v $PWD:/workspace \
            -w /workspace \
            alpine:latest \
            sh -c "rm -rf api/bin api/obj || true"

          # Clean up migration runner image if it exists
          docker rmi migration-runner:latest 2>/dev/null || true

          echo "✓ Cleanup completed!"
